{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c3bcc1d",
   "metadata": {},
   "source": [
    "# Constitutional Law LLM Training\n",
    "\n",
    "This notebook provides an interactive training workflow for the Constitutional Law LLM.\n",
    "\n",
    "## Overview\n",
    "- **Model**: OpenLLaMA with LoRA fine-tuning\n",
    "- **Data**: Supreme Court cases (First and Fourth Amendments)\n",
    "- **Task**: Constitutional law question answering\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfa88a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "# !pip install -r ../requirements.txt\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import torch\n",
    "import wandb\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append('../src')\n",
    "\n",
    "# Import our modules\n",
    "from config import config\n",
    "from data_processing import preprocess_data\n",
    "from model_training import ConstitutionalLawTrainer, train_model\n",
    "from model_utils import ModelManager\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0200f85",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Configure training parameters and paths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25fd6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure environment\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
    "\n",
    "# Set up wandb (optional)\n",
    "USE_WANDB = True\n",
    "if USE_WANDB and config.wandb_token:\n",
    "    wandb.login(key=config.wandb_token)\n",
    "    print(\"Weights & Biases configured successfully\")\n",
    "else:\n",
    "    print(\"Training without Weights & Biases logging\")\n",
    "    config.training.report_to = None\n",
    "\n",
    "# Training configuration\n",
    "TRAIN_CONFIG = {\n",
    "    'num_train_epochs': 3,\n",
    "    'per_device_train_batch_size': 2,\n",
    "    'learning_rate': 2e-4,\n",
    "    'weight_decay': 0.01,\n",
    "    'warmup_steps': 100,\n",
    "    'gradient_accumulation_steps': 4,\n",
    "    'logging_steps': 10,\n",
    "    'eval_steps': 500,\n",
    "    'save_steps': 500,\n",
    "    'fp16': True,\n",
    "    'gradient_checkpointing': True\n",
    "}\n",
    "\n",
    "# Model configuration\n",
    "MODEL_NAME = \"openlm-research/open_llama_7b\"\n",
    "OUTPUT_DIR = \"../models/constitutional_law_trained\"\n",
    "\n",
    "print(f\"Model: {MODEL_NAME}\")\n",
    "print(f\"Output directory: {OUTPUT_DIR}\")\n",
    "print(f\"Training config: {TRAIN_CONFIG}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc96bfb",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "Load and inspect the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234f68a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if processed data exists\n",
    "train_file = \"../data/processed/train_cleaned.jsonl\"\n",
    "val_file = \"../data/processed/validation_cleaned.jsonl\"\n",
    "\n",
    "if not os.path.exists(train_file) or not os.path.exists(val_file):\n",
    "    print(\"Processed data not found. Running preprocessing...\")\n",
    "    preprocess_data(\"../data/raw\", \"../data/processed\")\n",
    "    print(\"Preprocessing completed.\")\n",
    "else:\n",
    "    print(\"Using existing processed data.\")\n",
    "\n",
    "# Load and inspect data\n",
    "import json\n",
    "from datasets import load_dataset\n",
    "\n",
    "train_ds = load_dataset('json', data_files=train_file)['train']\n",
    "val_ds = load_dataset('json', data_files=val_file)['train']\n",
    "\n",
    "print(f\"Training examples: {len(train_ds)}\")\n",
    "print(f\"Validation examples: {len(val_ds)}\")\n",
    "\n",
    "# Show example\n",
    "print(\"\\nExample training instance:\")\n",
    "example = train_ds[0]\n",
    "print(f\"Case: {example['name']}\")\n",
    "print(f\"Instruction: {example['instruction'][:200]}...\")\n",
    "print(f\"Response: {example['response'][:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa479e02",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "\n",
    "Train the model with LoRA fine-tuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da273c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize trainer\n",
    "trainer = ConstitutionalLawTrainer(MODEL_NAME)\n",
    "\n",
    "print(\"Starting training...\")\n",
    "print(f\"Base model: {MODEL_NAME}\")\n",
    "print(f\"LoRA config: r={config.lora.r}, alpha={config.lora.lora_alpha}, dropout={config.lora.lora_dropout}\")\n",
    "\n",
    "# Train model\n",
    "training_results = trainer.train(\n",
    "    train_file=train_file,\n",
    "    val_file=val_file,\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    **TRAIN_CONFIG\n",
    ")\n",
    "\n",
    "print(\"\\nTraining completed!\")\n",
    "print(f\"Final training loss: {training_results['training_metrics'].get('train_loss', 'N/A')}\")\n",
    "print(f\"Final validation loss: {training_results['evaluation_metrics'].get('eval_loss', 'N/A')}\")\n",
    "print(f\"Final validation accuracy: {training_results['evaluation_metrics'].get('eval_accuracy', 'N/A')}\")\n",
    "print(f\"Model saved to: {training_results['model_path']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d1ece4",
   "metadata": {},
   "source": [
    "## Model Testing\n",
    "\n",
    "Test the trained model with sample questions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c00656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the trained model\n",
    "def test_model(model_path, test_questions):\n",
    "    \"\"\"Test the model with sample questions.\"\"\"\n",
    "    \n",
    "    # Load trained model\n",
    "    model_manager = ModelManager()\n",
    "    model_manager.load_model_local(model_path, MODEL_NAME)\n",
    "    \n",
    "    print(\"Testing trained model...\\n\")\n",
    "    \n",
    "    for i, test_case in enumerate(test_questions, 1):\n",
    "        print(f\"Test Case {i}:\")\n",
    "        print(f\"Facts: {test_case['facts']}\")\n",
    "        print(f\"Question: {test_case['question']}\")\n",
    "        \n",
    "        # Generate response\n",
    "        response = model_manager.generate_response(\n",
    "            test_case['facts'], \n",
    "            test_case['question']\n",
    "        )\n",
    "        \n",
    "        print(f\"Model Response: {response}\")\n",
    "        print(\"-\" * 80)\n",
    "\n",
    "# Sample test cases\n",
    "test_questions = [\n",
    "    {\n",
    "        \"facts\": \"A high school student wore a black armband to school to protest the Vietnam War. The school suspended the student for violating a policy against political demonstrations.\",\n",
    "        \"question\": \"Did the school's suspension of the student for wearing the armband violate the First Amendment?\"\n",
    "    },\n",
    "    {\n",
    "        \"facts\": \"Police officers conducted a warrantless search of a person's home after pursuing them for a misdemeanor traffic violation.\",\n",
    "        \"question\": \"Was the warrantless search constitutional under the Fourth Amendment?\"\n",
    "    },\n",
    "    {\n",
    "        \"facts\": \"A city passed an ordinance banning all public demonstrations in the downtown area, citing traffic concerns.\",\n",
    "        \"question\": \"Does this ordinance violate the First Amendment right to freedom of assembly?\"\n",
    "    }\n",
    "]\n",
    "\n",
    "test_model(OUTPUT_DIR, test_questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c02bdb8",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "Run comprehensive evaluation on test cases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b470aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test cases and evaluate\n",
    "test_file = \"../evaluation/test_cases.json\"\n",
    "\n",
    "if os.path.exists(test_file):\n",
    "    # Run evaluation\n",
    "    evaluation_results = trainer.evaluate(test_file)\n",
    "    \n",
    "    print(f\"Evaluation completed on {evaluation_results['total_cases']} test cases\")\n",
    "    \n",
    "    # Show some results\n",
    "    for i, result in enumerate(evaluation_results['results'][:3]):\n",
    "        print(f\"\\nTest Case {i+1}:\")\n",
    "        print(f\"Question: {result['question'][:100]}...\")\n",
    "        print(f\"Generated: {result['generated'][:150]}...\")\n",
    "        print(f\"Reference: {result['reference'][:150]}...\")\n",
    "        \n",
    "else:\n",
    "    print(f\"Test file not found: {test_file}\")\n",
    "    print(\"Using sample test cases instead.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37888047",
   "metadata": {},
   "source": [
    "## Save and Export\n",
    "\n",
    "Save the model for future use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310aad45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model locally (already done during training)\n",
    "print(f\"Model saved locally at: {OUTPUT_DIR}\")\n",
    "\n",
    "# Optionally save to Hugging Face Hub\n",
    "SAVE_TO_HUB = False  # Set to True to upload to HF Hub\n",
    "HF_MODEL_NAME = \"your-username/constitutional-law-llama\"  # Change this\n",
    "\n",
    "if SAVE_TO_HUB and config.hf_token:\n",
    "    print(\"Uploading to Hugging Face Hub...\")\n",
    "    trainer.model_manager.save_model_hub(HF_MODEL_NAME)\n",
    "    print(f\"Model uploaded to: https://huggingface.co/{HF_MODEL_NAME}\")\n",
    "else:\n",
    "    print(\"Skipping Hugging Face Hub upload\")\n",
    "\n",
    "# Save training summary\n",
    "summary = {\n",
    "    \"model_name\": MODEL_NAME,\n",
    "    \"training_config\": TRAIN_CONFIG,\n",
    "    \"lora_config\": {\n",
    "        \"r\": config.lora.r,\n",
    "        \"alpha\": config.lora.lora_alpha,\n",
    "        \"dropout\": config.lora.lora_dropout\n",
    "    },\n",
    "    \"data_stats\": {\n",
    "        \"train_examples\": len(train_ds),\n",
    "        \"val_examples\": len(val_ds)\n",
    "    },\n",
    "    \"results\": training_results\n",
    "}\n",
    "\n",
    "summary_file = os.path.join(OUTPUT_DIR, \"training_summary.json\")\n",
    "with open(summary_file, 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "print(f\"Training summary saved to: {summary_file}\")\n",
    "print(\"\\nTraining completed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
